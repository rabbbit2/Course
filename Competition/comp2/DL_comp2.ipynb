{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/datalab-cup2-object-detection-2020/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於資料量不足、資料類別間有數量不平衡的問題以及預防overfitting，我們對data做了下列處理：\n",
    "\n",
    "## (一)、解決imbalance問題\n",
    "\n",
    "我們將training data增加到了四萬多筆，以及盡量讓各組的類別數量平衡一點。\n",
    "\n",
    "## (二)、Data Augmentation\n",
    "同時，我們對圖片做了以下的處理：\n",
    "\n",
    "* 隨機抽樣圖片，把其中一個物件剪下來後，貼上在其他圖片上，增加圖片的多樣性。\n",
    "* 圖片的翻轉以及裁切。\n",
    "* 灰階處理。\n",
    "* gaussian_noise。\n",
    "* 亮度及不同顏色對比調整。\n",
    "\n",
    "但我們發現如果對所有圖片都做這些方法處理的話，模型會學得非常慢，而且\n",
    "也會造成某些物件完全學不到的結果，所以後來改成不會對每一張圖片都做所有augmentation方法，而是用類似抽樣的方式讓這些 augmentation方法被採用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "from shutil import copyfile\n",
    "# %%\n",
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "# %%\n",
    "# common params\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 6\n",
    "NUM_CLASSES = 20\n",
    "MAX_OBJECTS_PER_IMAGE = 20\n",
    "\n",
    "# dataset params\n",
    "\n",
    "DATA_PATH = './train_1.txt'\n",
    "IMAGE_DIR = './VOCdevkit_train/VOC2007/JPEGImages/'\n",
    "\n",
    "# model params\n",
    "CELL_SIZE = 7\n",
    "BOXES_PER_CELL = 2\n",
    "OBJECT_SCALE = 1\n",
    "NOOBJECT_SCALE = 0.5\n",
    "CLASS_SCALE = 1\n",
    "COORD_SCALE = 5\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 15\n",
    "\n",
    "is_fine_tune = False\n",
    "\n",
    "CKT_Dir = \"../ckpts/17_resnet_balance\"\n",
    "checkpoint_name = 'yolo_v1_17_resnet_balance'\n",
    "\n",
    "is_load_best = False\n",
    "\n",
    "PROB_THRES = 0.01\n",
    "IOU_THRES = 0.3\n",
    "# %%\n",
    "def list_add(a,b):\n",
    "    c = []\n",
    "    for i in range(len(a)):\n",
    "        c.append(a[i]+b[i])\n",
    "    return c\n",
    "\n",
    "training_data_file = open(\"./pascal_voc_training_data.txt\", \"r\")\n",
    "class imbalance:\n",
    "  def __init__(self):\n",
    "    self.each_class_count = []\n",
    "    self.each_pic_count = []\n",
    "    self.add_pic_index = []\n",
    "    self.new = []\n",
    "\n",
    "    for i, line in enumerate(training_data_file):\n",
    "      line = line.strip()\n",
    "      self.new.append(line)\n",
    "      a = line.split()\n",
    "      b = len(a)\n",
    "      e = []\n",
    "      for j in range(5,b,5):\n",
    "        e.append(a[j])\n",
    "        f = [e.count('0'),e.count('1'),e.count('2'),\n",
    "            e.count('3'),e.count('4'),e.count('5'),\n",
    "            e.count('6'),e.count('7'),e.count('8'),\n",
    "            e.count('9'),e.count('10'),e.count('11'),\n",
    "            e.count('12'),e.count('13'),e.count('14'),\n",
    "            e.count('15'),e.count('16'),e.count('17'),\n",
    "            e.count('18'),e.count('19')]\n",
    "      self.each_pic_count.append(f)\n",
    "    g = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(4974):\n",
    "      g = list_add(g,self.each_pic_count[i])\n",
    "    self.each_class_count = g \n",
    "    d = self.each_pic_count\n",
    "    \n",
    "    #index \n",
    "    index5 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][5]>0) and (d[i][14] == 0):\n",
    "        index5.append(i)\n",
    "    index10 = []\n",
    "    for i in range(4974):  \n",
    "      if (d[i][10]>0) and (d[i][14] < 2) and (d[i][8] < 3):\n",
    "        index10.append(i)\n",
    "    index0 = []\n",
    "    for i in range(4974): \n",
    "      if (d[i][0]>0) and (d[i][14] == 0) and (d[i][5] == 0)and (d[i][6] == 0) and(d[i][8] == 0) :\n",
    "        index0.append(i)\n",
    "    index18 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][18]>0) and (d[i][14] == 0) and (d[i][5] == 0)and (d[i][6] == 0) and(d[i][8] == 0) and (d[i][10] == 0) :\n",
    "        index18.append(i)\n",
    "    index19 = []\n",
    "    for i in range(4974):    \n",
    "      if (d[i][19]>0) and (d[i][14] == 0) and (d[i][8] == 0) and (d[i][10] == 0) and (d[i][0] == 0) and (d[i][18] == 0):\n",
    "        index19.append(i)\n",
    "    index9 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][9]>0) and (d[i][14] == 0):\n",
    "        index9.append(i)\n",
    "    index1 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][1]>0) and (d[i][14] == 0) :\n",
    "        index1.append(i)\n",
    "    index2 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][2]>0) and (d[i][14] == 0):\n",
    "        index2.append(i)\n",
    "    index3 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][3]>0) and (d[i][2]==0) and(d[i][14] == 0) :\n",
    "        index3.append(i)\n",
    "    index7 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][7]>0) and(d[i][14] == 0) :\n",
    "        index7.append(i)\n",
    "    index11 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][11]>0) and(d[i][14] == 0) :\n",
    "        index11.append(i)\n",
    "    index12 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][12]>0) and(d[i][14] == 0) :\n",
    "        index12.append(i)\n",
    "    index13 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][13]>0) and (d[i][14] == 0) and (d[i][6] == 0) and (d[i][10] == 0):\n",
    "        index13.append(i)\n",
    "    index16 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][16]>0) and (d[i][14] == 0) :\n",
    "        index16.append(i)\n",
    "    index17 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][17]>0) and (d[i][14] == 0) and (d[i][15] == 0)and (d[i][8] == 0) :\n",
    "        index17.append(i)\n",
    "    index4 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][4]>0) and(d[i][14] == 0) :\n",
    "        index4.append(i)\n",
    "    index15 = []\n",
    "    for i in range(4974):\n",
    "      if (d[i][15]>0) and(d[i][14] == 0) :\n",
    "        index15.append(i)\n",
    "    self.add_pic_index = list(np.repeat(index5,26))+list(np.repeat(index10,60))+list(np.repeat(index0,10))+list(np.repeat(index18,15))+list(np.repeat(index19,20))+list(np.repeat(index9,15))+list(np.repeat(index1,40))+list(np.repeat(index2,6))+list(np.repeat(index3,10))+list(np.repeat(index7,10))+list(np.repeat(index11,10))+list(np.repeat(index12,40))+list(np.repeat(index13,40))+list(np.repeat(index16,10))+list(np.repeat(index17,10))+list(np.repeat(index4,6))+list(np.repeat(index15,3))\n",
    "    for i in self.add_pic_index:\n",
    "      self.new.append(self.new[i])\n",
    "# %%\n",
    "# a = imbalance()\n",
    "\n",
    "# num = []\n",
    "# for line in a.new:\n",
    "#   line = line.strip()\n",
    "#   temp = line.split()\n",
    "#   for j in range(5,len(temp),5):\n",
    "#     num.append(temp[j])\n",
    "# #result = Counter(num)\n",
    "\n",
    "# new_data = a.new\n",
    "\n",
    "# with open('./train_1.txt', 'w') as f:\n",
    "#     for item in new_data:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "#%%\n",
    "@tf.function\n",
    "def random_flip(image,xcenter,ycenter):\n",
    "    up_down_outcome = tf.random.uniform([1],0,1)\n",
    "    right_left_outcome = tf.random.uniform([1],0,1)\n",
    "\n",
    "    x_0 = tf.not_equal(xcenter,0.)\n",
    "    y_0 = tf.not_equal(ycenter,0.)\n",
    "    grand = tf.cast(tf.where(tf.math.logical_or(x_0,y_0),IMAGE_SIZE,0),\n",
    "                    tf.float32)\n",
    "\n",
    "    if up_down_outcome<up_down_flip_p:\n",
    "        image = tf.image.flip_up_down(image)\n",
    "        ycenter = grand-ycenter\n",
    "\n",
    "    if right_left_outcome<left_right_flip_p:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        xcenter = grand-xcenter\n",
    "\n",
    "    return image, xcenter, ycenter\n",
    "\n",
    "@tf.function\n",
    "def to_gray(image):\n",
    "    prob = tf.random.uniform([1],0,1)\n",
    "\n",
    "    if prob<gray_p:\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def gaussian_noise(image):\n",
    "    prob = tf.random.uniform([1],0,1)\n",
    "    \n",
    "    if prob<noise_p:\n",
    "        noise = tf.random.normal(image.shape,stddev=5)\n",
    "        image = tf.math.add(image, noise)\n",
    "        \n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def brightness(image):\n",
    "    prob = tf.random.uniform([1],0,1)\n",
    "    \n",
    "    if prob<brightness_p:\n",
    "        image = tf.image.random_brightness(image,5)\n",
    "        \n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def hue(image):\n",
    "    prob = tf.random.uniform([1], 0, 1)\n",
    "    \n",
    "    if prob < hue_p:\n",
    "        image = tf.image.random_hue(image, 0.5)\n",
    "        \n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def saturation(image):\n",
    "    prob = tf.random.uniform([1], 0, 1)\n",
    "    \n",
    "    if prob < saturation_p:\n",
    "        image = tf.image.random_saturation(image, 0, 1.5)\n",
    "        \n",
    "    return image\n",
    "# %%\n",
    "# data augumentation parameter\n",
    "up_down_flip_p = 0.05\n",
    "left_right_flip_p = 0.5\n",
    "\n",
    "theSame = 0.4\n",
    "crop_p = 0.6\n",
    "geom_p = 0.8\n",
    "brightness_p = 0.3\n",
    "hue_p = 0.8\n",
    "saturation_p = 0.8\n",
    "contrast = 0.3\n",
    "gray_p = 0.1\n",
    "noise_p = 0.4\n",
    "blur = 0.2\n",
    "\n",
    "rotate_range=(-45, 45)\n",
    "scale_range=(0.2, 1.2)\n",
    "translate_range=(-0.2, 0.2)\n",
    "shear_range=(-20, 20)\n",
    "crop_pad_range=(-0.2, 0.2)\n",
    "#%%\n",
    "def imgaug_trans(image,labels):\n",
    "    n = tf.math.count_nonzero(labels[:,0]).numpy()\n",
    "    image = image.numpy()\n",
    "    labels = labels.numpy()\n",
    "    output = np.zeros_like(labels)\n",
    "\n",
    "    center_x = labels[:,0]\n",
    "    center_y = labels[:,1]\n",
    "    w_half = labels[:,2] / 2\n",
    "    h_half = labels[:,3] / 2\n",
    "\n",
    "    tempbb = [BoundingBox(x1=center_x[i] - w_half[i], y1=center_y[i] - h_half[i],\n",
    "                          x2=center_x[i] + w_half[i], y2=center_y[i] + h_half[i]) for i in range(n)]\n",
    "    bbs = BoundingBoxesOnImage(tempbb, shape=image.shape)\n",
    "\n",
    "    seq = iaa.Sequential(\n",
    "      [\n",
    "       iaa.Sometimes(crop_p,iaa.CropAndPad(percent=(crop_pad_range[0], crop_pad_range[1]))),\n",
    "       iaa.Sometimes(geom_p,\n",
    "                     iaa.SomeOf((1, 5),[\n",
    "                                       iaa.Affine(translate_percent={\"x\":(translate_range[0], translate_range[1])}),\n",
    "                                       iaa.Affine(translate_percent={\"y\":(translate_range[0], translate_range[1])}),\n",
    "                                       iaa.Affine(scale=(scale_range[0], scale_range[1])),\n",
    "                                       iaa.Affine(rotate=(rotate_range[0], rotate_range[1])),\n",
    "                                       iaa.Affine(shear=(shear_range[0],shear_range[1]))\n",
    "                                       ],\n",
    "                                random_order=True)\n",
    "                     ),\n",
    "       iaa.Sometimes(contrast,\n",
    "                     iaa.OneOf([\n",
    "                                iaa.contrast.LinearContrast(alpha=(1.25, 1.5),per_channel=True),\n",
    "                                iaa.contrast.LinearContrast(alpha=(0.25, 0.5),per_channel=True),\n",
    "                                iaa.contrast.LinearContrast(alpha=(0.25, 0.5)),\n",
    "                                iaa.contrast.LinearContrast(alpha=(1.25, 1.5)),\n",
    "                                iaa.ChannelShuffle()\n",
    "                                ]\n",
    "                               )\n",
    "                     ),\n",
    "       iaa.Sometimes(blur, iaa.GaussianBlur(sigma=(0.1,3)))\n",
    "    ])\n",
    "\n",
    "    image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)\n",
    "\n",
    "    if len(bbs_aug.remove_out_of_image().bounding_boxes)==n:\n",
    "        theIdx = [i for i in range(n)]\n",
    "    else:\n",
    "        set_bb = set(bbs_aug.remove_out_of_image().bounding_boxes)\n",
    "        theIdx = [i for i in range(n) if bbs_aug.bounding_boxes[i] in set_bb]\n",
    "\n",
    "    remain_labels = labels[theIdx, 4]\n",
    "    clip_bbs = bbs_aug.remove_out_of_image().clip_out_of_image().bounding_boxes\n",
    "    for i in range(len(theIdx)):\n",
    "        theBox = clip_bbs[i]\n",
    "        output[i, 0] = (theBox.x1 + theBox.x2) / 2 # x center\n",
    "        output[i, 1] = (theBox.y1 + theBox.y2) / 2 # y center\n",
    "        output[i, 2] = (theBox.x2 - theBox.x1) # w\n",
    "        output[i, 3] = (theBox.y2 - theBox.y1) # h\n",
    "        output[i, 4] = remain_labels[i]\n",
    "\n",
    "    return image_aug, output\n",
    "#%%\n",
    "@tf.function\n",
    "def data_aug(image,labels):\n",
    "    same_sample = tf.random.uniform([1],0,1)\n",
    "    if same_sample > theSame:\n",
    "        # not the same\n",
    "        image = gaussian_noise(image)\n",
    "        image, labels = tf.py_function(\n",
    "            func=imgaug_trans,\n",
    "            inp=[image, labels],\n",
    "            Tout=[tf.float32, tf.float32]\n",
    "            )\n",
    "        image = brightness(image)\n",
    "        image = hue(image)\n",
    "        image = saturation(image)\n",
    "        image = to_gray(image)\n",
    "\n",
    "    return image, labels\n",
    "#%%\n",
    "class DatasetGenerator:\n",
    "    \"\"\"\n",
    "    Load pascalVOC 2007 dataset and creates an input pipeline ready to be fed into a model.\n",
    "    - Reshapes images into 448 x 448\n",
    "    - converts [0 1] to [-1 1]\n",
    "    - shuffles the input\n",
    "    - builds batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_names = []\n",
    "        self.record_list = []\n",
    "        self.object_num_list = []\n",
    "        # filling the record_list\n",
    "        input_file = open(DATA_PATH, 'r')\n",
    "\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            \n",
    "            self.image_names.append(ss[0])\n",
    "            self.record_list.append([float(num) for num in ss[1:]])\n",
    "            self.object_num_list.append(min(len(self.record_list[-1])//5, MAX_OBJECTS_PER_IMAGE))\n",
    "            \n",
    "            # resize newest data\n",
    "            if len(self.record_list[-1]) < MAX_OBJECTS_PER_IMAGE*5:\n",
    "                self.record_list[-1] = self.record_list[-1] +\\\n",
    "                [0., 0., 0., 0., 0.]*\\\n",
    "                (MAX_OBJECTS_PER_IMAGE-len(self.record_list[-1])//5)\n",
    "            elif len(self.record_list[-1]) > MAX_OBJECTS_PER_IMAGE*5:\n",
    "                self.record_list[-1] = self.record_list[-1][:MAX_OBJECTS_PER_IMAGE*5]\n",
    "                \n",
    "        ## shuffle\n",
    "        idx = random.sample(range(len(self.image_names)), len(self.image_names))\n",
    "        self.image_names = [self.image_names[i] for i in idx]\n",
    "        self.record_list = [self.record_list[i] for i in idx]\n",
    "        self.object_num_list = [self.object_num_list[i] for i in idx]\n",
    "\n",
    "    def _data_preprocess(self, image_name, raw_labels, object_num):\n",
    "        image_file = tf.io.read_file(IMAGE_DIR+image_name)\n",
    "        image = tf.io.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "        h = tf.shape(image)[0]\n",
    "        w = tf.shape(image)[1]\n",
    "\n",
    "        width_rate = IMAGE_SIZE * 1.0 / tf.cast(w, tf.float32) \n",
    "        height_rate = IMAGE_SIZE * 1.0 / tf.cast(h, tf.float32) \n",
    "\n",
    "        image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "\n",
    "        raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "\n",
    "        xmin = raw_labels[:, 0]\n",
    "        ymin = raw_labels[:, 1]\n",
    "        xmax = raw_labels[:, 2]\n",
    "        ymax = raw_labels[:, 3]\n",
    "        class_num = raw_labels[:, 4]\n",
    "\n",
    "        xcenter = (xmin + xmax) * 1.0 / 2.0 * width_rate\n",
    "        ycenter = (ymin + ymax) * 1.0 / 2.0 * height_rate\n",
    "\n",
    "        box_w = (xmax - xmin) * width_rate\n",
    "        box_h = (ymax - ymin) * height_rate\n",
    "\n",
    "        image, xcenter, ycenter = random_flip(image, xcenter, ycenter)\n",
    "\n",
    "        labels = tf.stack([xcenter, ycenter, box_w, box_h, class_num], axis = 1)\n",
    "\n",
    "        image, labels = data_aug(image, labels)\n",
    "        image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "\n",
    "        return image, labels, tf.cast(object_num, tf.int32)\n",
    "\n",
    "    def generate(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.image_names, \n",
    "                                                      np.array(self.record_list), \n",
    "                                                      np.array(self.object_num_list)))\n",
    "        dataset = dataset.map(self._data_preprocess, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(1000)\n",
    "        dataset = dataset.batch(BATCH_SIZE)\n",
    "        \n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#%%\n",
    "DATA_PATH = './pascal_voc_training_data.txt'\n",
    "IMAGE_DIR = './VOCdevkit_train/VOC2007/JPEGImages/'\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 6\n",
    "NUM_CLASSES = 20\n",
    "MAX_OBJECTS_PER_IMAGE = 20\n",
    "\n",
    "#%%\n",
    "image_names = []\n",
    "record_list = []\n",
    "object_num_list = []\n",
    "# filling the record_list\n",
    "input_file = open(DATA_PATH, 'r')\n",
    "#%%\n",
    "for line in input_file:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    image_names.append(ss[0])\n",
    "    record_list.append([float(num) for num in ss[1:]])\n",
    "\n",
    "    object_num_list.append(min(len(record_list[-1])//5, \n",
    "                                    MAX_OBJECTS_PER_IMAGE))\n",
    "    if len(record_list[-1]) < MAX_OBJECTS_PER_IMAGE*5:\n",
    "        record_list[-1] = record_list[-1] +\\\n",
    "        [0., 0., 0., 0., 0.]*\\\n",
    "        (MAX_OBJECTS_PER_IMAGE-len(record_list[-1])//5)\n",
    "                \n",
    "    elif len(record_list[-1]) > MAX_OBJECTS_PER_IMAGE*5:\n",
    "        record_list[-1] = record_list[-1][:MAX_OBJECTS_PER_IMAGE*5]\n",
    "#%%\n",
    "image_collect = []\n",
    "label_collect = []\n",
    "object_num_collect = []\n",
    "for image_name,raw_labels,obj_n in zip(image_names,record_list,object_num_list):\n",
    "    image_file = tf.io.read_file(IMAGE_DIR+image_name)\n",
    "    image = tf.io.decode_jpeg(image_file, channels=3)\n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "    raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "    image_collect.append(image)\n",
    "    label_collect.append(raw_labels)\n",
    "    object_num_collect.append(obj_n)\n",
    "\n",
    "#%%\n",
    "def sample_cut(image_collect,label_collect,object_num_collect):\n",
    "    p = [1/20 for i in range(20)]\n",
    "    # random 抽一張要黏貼的圖\n",
    "    wanted = np.where(np.random.multinomial(1,p, size=None))[0][0]\n",
    "    random_object = np.random.randint(0,4973)\n",
    "    cut_label = label_collect[random_object].numpy()\n",
    "    cut_obj_n = object_num_collect[random_object]\n",
    "    cut_label = cut_label[0:cut_obj_n]\n",
    "    if (wanted in cut_label[:,4]):\n",
    "        cut_img = image_collect[random_object].numpy()\n",
    "    else:\n",
    "        while(wanted not in cut_label[:,4]):\n",
    "            random_object = np.random.randint(0,4973)\n",
    "            cut_label = label_collect[random_object].numpy()\n",
    "            cut_obj_n = object_num_collect[random_object]\n",
    "            cut_label = cut_label[0:cut_obj_n]\n",
    "        cut_img = image_collect[random_object].numpy()\n",
    "    # 記錄出物件的 xmin,ymin,xmax,ymax\n",
    "    label = cut_label[wanted==cut_label[:,4]].astype(\"int32\")[0]\n",
    "    # 把物件剪下來\n",
    "    sub_obj = cut_img[label[1]:label[3],label[0]:label[2]]\n",
    "    return sub_obj,label\n",
    "def sample_paste(image_collect,label_collect,object_num_collect):\n",
    "    # sample 一張要被貼的圖片\n",
    "    random_paste = np.random.randint(0,4973)\n",
    "    paste_label = label_collect[random_paste].numpy()\n",
    "    paste_obj_n = object_num_collect[random_paste]\n",
    "    if (14 not in paste_label[:,4] and paste_label.shape[0]!=20):\n",
    "        paste_img = image_collect[random_paste].numpy()\n",
    "    else:\n",
    "        while(14 in paste_label[:,4] or paste_obj_n==20):\n",
    "            random_paste = np.random.randint(0,4973)\n",
    "            paste_label = label_collect[random_paste].numpy()\n",
    "            paste_obj_n = object_num_collect[random_paste]        \n",
    "        paste_img = image_collect[random_paste].numpy()\n",
    "    return paste_img,paste_label,paste_obj_n\n",
    "def calculate_area(label):\n",
    "    return (label[2]-label[0])*(label[3]-label[1])\n",
    "def max_label_sample(paste_label,paste_obj_n,p_1,p_2):\n",
    "    if paste_obj_n>1:\n",
    "        area = []\n",
    "        for i in range(paste_obj_n):\n",
    "            area.append(calculate_area(paste_label[i,0:4]))\n",
    "        max_pos = np.where(area==np.max(area))[0][0]\n",
    "    else:\n",
    "        max_pos = 0\n",
    "    xmin = paste_label[max_pos,0]\n",
    "    ymin = paste_label[max_pos,1]\n",
    "    xmax = paste_label[max_pos,2]\n",
    "    ymax = paste_label[max_pos,3]\n",
    "    if xmin-0>p_2-xmax:\n",
    "        top_left_2 = np.random.randint(0,xmin)\n",
    "    else:\n",
    "        top_left_2 = np.random.randint(xmax,p_2)\n",
    "    if ymin-0>p_1-ymax:\n",
    "        top_left_1 = np.random.randint(0,ymin)\n",
    "    else:\n",
    "        top_left_1 = np.random.randint(0,p_1)\n",
    "    \n",
    "    return top_left_1,top_left_2\n",
    "\n",
    "def iou(boxes1,boxes2):\n",
    "    #calculate the left up point of boxes' overlap area\n",
    "    lu = np.maximum(boxes1[0:2], boxes2[0:2])\n",
    "    #calculate the right down point of boxes overlap area\n",
    "    rd = np.minimum(boxes1[2:], boxes2[2:])\n",
    "\n",
    "    #intersection\n",
    "    intersection = rd - lu\n",
    "\n",
    "    #the size of the intersection area\n",
    "    inter_square = intersection[0] * intersection[1]\n",
    "\n",
    "    mask = ((intersection[0] > 0) * (intersection[1] > 0))*1.\n",
    "\n",
    "    #if intersection is negative, then the boxes don't overlap\n",
    "    inter_square = mask * inter_square\n",
    "\n",
    "    #calculate the boxs1 square and boxs2 square\n",
    "    square1 = (boxes1[2] - boxes1[0]) * (boxes1[3] - boxes1[1])\n",
    "    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "    return inter_square/square2\n",
    "def iou_procedure(new_sub_1,new_sub_2,top_left_1,top_left_2,p_1,p_2,paste_label,paste_obj_n):\n",
    "    iou_out = []\n",
    "    if (new_sub_1+top_left_1)<p_1 and (new_sub_2+top_left_2)<p_2:\n",
    "        new_pos = np.array([top_left_2,top_left_1,top_left_2+new_sub_2,top_left_1+new_sub_1],dtype=float)\n",
    "        for i in range(paste_obj_n):\n",
    "            iou_out.append(iou(new_pos,paste_label[i,:4]))\n",
    "    else:\n",
    "        i=0\n",
    "        while((new_sub_1+top_left_1)>p_1 or (new_sub_2+top_left_2)>p_2):\n",
    "            if i%5==4: new_sub_1,new_sub_2 =new_sub_1*(0.9),new_sub_2*(0.9)\n",
    "            top_left_1,top_left_2 = max_label_sample(paste_label,paste_obj_n,p_1,p_2)\n",
    "            print(i)\n",
    "            i+=1\n",
    "            if i>1000: \n",
    "                new_pos = [0.,0.,0.,0.]\n",
    "                iou_out = [5]\n",
    "                break\n",
    "        new_pos = np.array([top_left_2,top_left_1,top_left_2+new_sub_2,top_left_1+new_sub_1],dtype=float)\n",
    "        for i in range(paste_obj_n):\n",
    "            iou_out.append(iou(new_pos,paste_label[i,:4]))\n",
    "    return np.array(iou_out),new_pos\n",
    "def add_data(image_collect,label_collect,object_num_collect):\n",
    "    # sample cut\n",
    "    sub_obj,label = sample_cut(image_collect,label_collect,object_num_collect)\n",
    "    sub_1,sub_2,_ = sub_obj.shape\n",
    "    print(1)\n",
    "    # sample paste\n",
    "    paste_img,paste_label,paste_obj_n = sample_paste(image_collect,label_collect,object_num_collect)\n",
    "    p_1,p_2,_ = paste_img.shape\n",
    "    print(2)\n",
    "    # 將長寬縮放任二 ratio (random sample)，記錄新的圖片與新的長寬\n",
    "    if (sub_1>p_1-20) or (sub_2>p_2-20):\n",
    "        new_sub_1,new_sub_2 = sub_1*0.5,sub_2*0.5\n",
    "    ratio = np.random.uniform(0.5,1.5,1)[0]\n",
    "    new_sub_1,new_sub_2 = np.around(sub_1*ratio,0).astype('int32'),np.around(sub_2*ratio,0).astype('int32')\n",
    "    top_left_1,top_left_2 = max_label_sample(paste_label,paste_obj_n,p_1,p_2)\n",
    "    print(3)\n",
    "    # iou threshold 0.2\n",
    "    iou_out,new_pos = iou_procedure(new_sub_1,new_sub_2,top_left_1,top_left_2,p_1,p_2,paste_label,paste_obj_n)\n",
    "    area = calculate_area(new_pos)\n",
    "    return iou_out,new_pos,area,label,paste_img,paste_label,paste_obj_n,sub_obj\n",
    "# %%\n",
    "\n",
    "f = open('somefile.txt', 'w')\n",
    "for k in range(5000):\n",
    "    iou_out,new_pos,area,label,paste_img,paste_label,paste_obj_n,sub_obj = add_data(image_collect,label_collect,object_num_collect)\n",
    "    print(4)\n",
    "    w,h,_ = paste_img.shape\n",
    "    thd = w*h/49\n",
    "    if np.sum(iou_out>=0.2)!=0 or area<thd:\n",
    "        j=0\n",
    "        while np.sum(iou_out>=0.2)!=0 or area<thd:\n",
    "            iou_out,new_pos,area,label,paste_img,paste_label,paste_obj_n,sub_obj = add_data(image_collect,label_collect,object_num_collect)\n",
    "            j+=1\n",
    "    label[0:4]=new_pos\n",
    "    paste_label[paste_obj_n]=label\n",
    "    paste_obj_n+=1\n",
    "    new_pos = new_pos.astype('int32')\n",
    "    sub_obj = cv2.resize(sub_obj, (new_pos[2]-new_pos[0], new_pos[3]-new_pos[1]), interpolation=cv2.INTER_CUBIC)\n",
    "    paste_img[new_pos[1]:new_pos[3],new_pos[0]:new_pos[2]]=sub_obj\n",
    "    words = np.reshape(paste_label[:paste_obj_n].astype('int32'),[5*paste_obj_n]).astype(\"str\").tolist()\n",
    "    \n",
    "    f.write(str(k)+\".jpg \"+\" \".join(words)+\"\\n\")  # python will convert \\n to os.linesep\n",
    "    paste_img = cv2.cvtColor(paste_img, cv2.COLOR_RGB2BGR) \n",
    "    cv2.imwrite(\"C:\\\\Users\\\\linre\\\\Desktop\\\\DL_HW\\\\DL_competition_2\\\\img_file\\\\\"+str(k)+\".jpg \",paste_img)\n",
    "f.close() \n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、 Model Building\n",
    "做完Data preprocessing後，接下來我們嘗試用各種model建模，並切validation data來判斷模型訓練過程當中的好壞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np \n",
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[5], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common params\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 100\n",
    "VAL_BATCH_SIZE = 200\n",
    "NUM_CLASSES = 20\n",
    "MAX_OBJECTS_PER_IMAGE = 42\n",
    "\n",
    "# dataset params\n",
    "DATA_PATH = './train_1.txt'\n",
    "IMAGE_DIR = './VOCdevkit_train/VOC2007/JPEGImages/'\n",
    "\n",
    "# model params\n",
    "CELL_SIZE = 7\n",
    "BOXES_PER_CELL = 2\n",
    "OBJECT_SCALE = 1\n",
    "NOOBJECT_SCALE = 0.5\n",
    "CLASS_SCALE = 1\n",
    "COORD_SCALE = 5\n",
    "pretrain_model_list =  ['EfficientNetB0','Xception','Resnet','DenseNet121']\n",
    "pretrain_model = pretrain_model[0]\n",
    "# training params\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_flip_and_coordinate(image,labels,num_classes):\n",
    "    if tf.random.uniform([1],0,1)>=0.4:\n",
    "        w,h,_ = image.shape\n",
    "        x_center = tf.concat([w-labels[0:(num_classes),0],tf.zeros(MAX_OBJECTS_PER_IMAGE-num_classes)],axis=0)\n",
    "        labels = tf.stack([x_center,labels[:,1],labels[:,2],labels[:,3],labels[:,4]],\n",
    "                            axis=1)\n",
    "        image = tf.image.flip_left_right(image)\n",
    "    else:\n",
    "        pass;\n",
    "    return  image,labels\n",
    "def random_noise(image,k):\n",
    "    num = tf.random.uniform([1],1,k,tf.dtypes.int32)[0]\n",
    "    h,w,_ = image.shape\n",
    "    coordinate = tf.range(0,h+1,448//k)\n",
    "    for j in range(num):\n",
    "        w_loc = tf.random.uniform([1],1,k,tf.dtypes.int32)[0]\n",
    "        h_loc = tf.random.uniform([1],1,k,tf.dtypes.int32)[0]\n",
    "        indices = tf.reshape(tf.range(coordinate[w_loc-1],coordinate[w_loc]),[coordinate[w_loc]-coordinate[w_loc-1],1])\n",
    "        noise = tf.random.normal((w//k,h//k,3),0,0.8)\n",
    "        tensor = tf.ones([w,h//k,3],dtype=tf.dtypes.float32)\n",
    "        noise = tf.tensor_scatter_nd_update(tensor, indices, noise)\n",
    "        noise = tf.transpose(noise,[1,0,2])\n",
    "        indices = tf.reshape(tf.range(coordinate[h_loc-1],coordinate[h_loc]),[coordinate[h_loc]-coordinate[h_loc-1],1])\n",
    "        tensor = tf.ones([w,h,3],dtype=tf.dtypes.float32)\n",
    "        noise = tf.tensor_scatter_nd_update(tensor, indices, noise)\n",
    "        noise = tf.transpose(noise,[1,0,2])\n",
    "        image = image*noise\n",
    "    return(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    \"\"\"\n",
    "    Load pascalVOC 2007 dataset and creates an input pipeline.\n",
    "    - Reshapes images into 448 x 448\n",
    "    - converts [0 1] to [-1 1]\n",
    "    - shuffles the input\n",
    "    - builds batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,test_size=0.2,random_state=0):\n",
    "        image_names = []\n",
    "        record_list = []\n",
    "        object_num_list = []\n",
    "        # filling the record_list\n",
    "        input_file = open(DATA_PATH, 'r')\n",
    "  \n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            image_names.append(ss[0])\n",
    "\n",
    "            record_list.append([float(num) for num in ss[1:]])\n",
    "\n",
    "            object_num_list.append(min(len(record_list[-1])//5, \n",
    "                                            MAX_OBJECTS_PER_IMAGE))\n",
    "            if len(record_list[-1]) < MAX_OBJECTS_PER_IMAGE*5:\n",
    "                # if there are objects less than MAX_OBJECTS_PER_IMAGE, pad the list\n",
    "                record_list[-1] = record_list[-1] +                [0., 0., 0., 0., 0.]*                (MAX_OBJECTS_PER_IMAGE-len(record_list[-1])//5)\n",
    "                \n",
    "            elif len(record_list[-1]) > MAX_OBJECTS_PER_IMAGE*5:\n",
    "               # if there are objects more than MAX_OBJECTS_PER_IMAGE, crop the list\n",
    "                record_list[-1] = record_list[-1][:MAX_OBJECTS_PER_IMAGE*5]\n",
    "        self.image_names_train, self.image_names_val, self.record_list_train, self.record_list_val,self.object_num_list_train,self.object_num_list_val = train_test_split(image_names, record_list,object_num_list, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    def _data_preprocess(self, image_name, raw_labels, object_num):\n",
    "        image_file = tf.io.read_file(IMAGE_DIR+image_name)\n",
    "        image = tf.io.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "        h = tf.shape(image)[0]\n",
    "        w = tf.shape(image)[1]\n",
    "\n",
    "        width_ratio  = IMAGE_SIZE * 1.0 / tf.cast(w, tf.float32) \n",
    "        height_ratio = IMAGE_SIZE * 1.0 / tf.cast(h, tf.float32) \n",
    "\n",
    "        image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "        # image = (image/255) * 2 - 1\n",
    "        if pretrain_model == 'Resnet':\n",
    "            image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "        elif pretrain_model == 'Xception':\n",
    "            image = tf.keras.applications.xception.preprocess_input(image)\n",
    "        elif pretrain_model == 'EfficientNetB0':\n",
    "            image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
    "        elif pretrain_model == 'DenseNet121':\n",
    "            image = tf.keras.applications.densenet.preprocess_input(image)\n",
    "        raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "\n",
    "        xmin = raw_labels[:, 0]\n",
    "        ymin = raw_labels[:, 1]\n",
    "        xmax = raw_labels[:, 2]\n",
    "        ymax = raw_labels[:, 3]\n",
    "        class_num = raw_labels[:, 4]\n",
    "\n",
    "        xcenter = (xmin + xmax) * 1.0 / 2.0 * width_ratio\n",
    "        ycenter = (ymin + ymax) * 1.0 / 2.0 * height_ratio\n",
    "\n",
    "        box_w = (xmax - xmin) * width_ratio\n",
    "        box_h = (ymax - ymin) * height_ratio\n",
    "\n",
    "        labels = tf.stack([xcenter, ycenter, box_w, box_h, class_num], axis=1)\n",
    "\n",
    "        return image, labels, tf.cast(object_num, tf.int32)\n",
    "    def _map_fun(self,image,labels,object_num):\n",
    "        image= tf.image.random_brightness(image, max_delta=2)\n",
    "        image = tf.image.random_contrast(image, lower=0.4, upper=2)\n",
    "        image = tf.image.random_hue(image,max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image,lower=0,upper=1)\n",
    "        image = random_noise(image,k=10)\n",
    "        image,labels = image_flip_and_coordinate(image,labels,object_num)\n",
    "        \n",
    "        return image,labels,object_num\n",
    "\n",
    "    def generate(self):\n",
    "        \n",
    "        # train data\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((self.image_names_train, \n",
    "                                                      np.array(self.record_list_train), \n",
    "                                                      np.array(self.object_num_list_train)))\n",
    "        train_dataset = train_dataset.shuffle(100000)\n",
    "            \n",
    "        train_dataset = train_dataset.map(self._data_preprocess, \n",
    "                              num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "        train_dataset = train_dataset.map(self._map_fun, \n",
    "                              num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        train_dataset = train_dataset.batch(BATCH_SIZE,True)\n",
    "        train_dataset = train_dataset.prefetch(buffer_size=1000)\n",
    "\n",
    "        return train_dataset\n",
    "\n",
    "    def generate_val(self):\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((self.image_names_val, \n",
    "                                                      np.array(self.record_list_val), \n",
    "                                                      np.array(self.object_num_list_val)))\n",
    "        val_dataset = val_dataset.map(self._data_preprocess, \n",
    "                              num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        val_dataset = val_dataset.batch(VAL_BATCH_SIZE,True)\n",
    "\n",
    "        val_dataset = val_dataset.prefetch(buffer_size=1000)\n",
    "        return val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (一)、Pre-trained model \n",
    "* 我們曾經嘗試不同的 pre-trained model，包含 ResNet152、Xception、EfficientNetB0、DenseNet121。\n",
    "* 由於時間因素，我們暫時將Pre-trained model 的layers 凍結住 ，雖然說 Pre-trained model中的係數，並不是用來針對YOLO 做最佳化的，我們目前只將 Pre-trained model 作為 類似feature 提去的方式，然會對我們自己設計的 yolo 模型 做最佳化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet152,Xception,EfficientNetB0,DenseNet121\n",
    "\n",
    "def conv_leaky_relu(inputs, filters, size, stride):\n",
    "    x = layers.Conv2D(filters, size, stride, padding=\"same\",\n",
    "                    kernel_initializer=tf.keras.initializers.TruncatedNormal())(inputs)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "    return x\n",
    "\n",
    "if pretrain_model == 'Resnet':\n",
    "    base_model = ResNet152(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(448,448,3),\n",
    "        pooling=None)\n",
    "elif pretrain_model == 'Xception':\n",
    "    base_model = Xception(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(448,448,3),\n",
    "        pooling=None)\n",
    "elif pretrain_model == 'EfficientNetB0':\n",
    "    base_model = EfficientNetB0(\n",
    "        include_top=False, \n",
    "        weights='imagenet', \n",
    "        input_shape=(448,448,3),\n",
    "        pooling=None)\n",
    "elif pretrain_model == 'DenseNet121':\n",
    "    base_model = DenseNet121(\n",
    "        include_top=False, \n",
    "        weights='imagenet', \n",
    "        input_shape=(448,448,3),\n",
    "        pooling=None)\n",
    "for layer in base_model.layers:\n",
    "    if layer.name in ['No']:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (二)、Model construction\n",
    "我們在pre-trained model 後仿造paper 前三層 接上三層 Convolution+Leaky ReLU ，其中第四層開始，與助教提供的示範 code 不一樣的是，依照我們自己認為預測的重要程度 從 class_prob , object_prob 到位置 location 分別依序把多維的輸入壓扁為一維輸出(接上扁平層)後，接上全連接階層(Dense)， sequential 將計算Loss 所需要的維度作為模型的輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "class network(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(network,self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.conv_1 = layers.Conv2D(1024,3,1)\n",
    "        self.conv_2 = layers.Conv2D(1024,3,2)\n",
    "        self.conv_3 = layers.Conv2D(1024,3,1)\n",
    "        #self.conv_4 = layers.Conv2D(20,1,1)\n",
    "        #self.conv_5 = layers.Conv2D(1024,1,1)\n",
    "        self.dense_1 = layers.Dense(98,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "        self.dense_2 = layers.Dense(392,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "        self.dense_3 = layers.Dense(980,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "        self.dense_4 = layers.Dense(2048,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "        self.dense_5 = layers.Dense(2048,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "        self.dense_6 = layers.Dense(2048,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "        # self.dense_7 = layers.Dense(1024,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "        # self.dense_8 = layers.Dense(1024,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "        # self.dense_9 = layers.Dense(1024,kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))\n",
    "    def call(self,inputs):\n",
    "        x=base_model(inputs)\n",
    "        x=self.conv_1(x)\n",
    "        x=layers.LeakyReLU(0.1)(x)\n",
    "        x=self.conv_2(x)\n",
    "        x=layers.LeakyReLU(0.1)(x)\n",
    "        x=self.conv_3(x)\n",
    "        x=layers.LeakyReLU(0.1)(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        c = self.dense_4(x)\n",
    "        c=layers.LeakyReLU(0.1)(c)\n",
    "        class_prob = self.dense_3(c)\n",
    "\n",
    "        #class_prob = tf.nn.sigmoid(class_prob)\n",
    "        class_prob = tf.reshape(class_prob,[-1,7,7,20])\n",
    "        #x = tf.concat([c,class_prob],-1)\n",
    "        c = self.dense_5(c)\n",
    "        c=layers.LeakyReLU(0.1)(c)\n",
    "        object_prob = self.dense_1(c)\n",
    "        object_prob = tf.reshape(object_prob,[-1,7,7,2])\n",
    "\n",
    "        # x = tf.concat([x,object_prob],-1)\n",
    "        c = self.dense_6(c)\n",
    "        c=layers.LeakyReLU(0.1)(c)\n",
    "        # x = self.conv_5(x)\n",
    "        #x = layers.Flatten()(x)\n",
    "        bbox = self.dense_2(c)\n",
    "        bbox = tf.reshape(bbox,[-1,7,7,8])\n",
    "\n",
    "        #outputs=layers.Flatten()(tf.concat([class_prob,object_prob,bbox],-1))\n",
    "        return [class_prob,object_prob,bbox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "\n",
    "YOLO = network()\n",
    "outputs=YOLO(img_inputs)\n",
    "YOLO.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (三)、Loss\n",
    "我們有嘗試改寫yolo loss 的定義，我們認為在計算probability時，並不應該使用 L2 norm, 應該改採用 entropy 的方式計算，但在幾次試驗之後發現，如此更改Loss 會導致原先yolo loss 的比重需要做相當程度的調整，最後我們還是採用助教提供的loss 定義方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base boxes (for loss calculation)\n",
    "base_boxes = np.zeros([CELL_SIZE, CELL_SIZE, 4])\n",
    "\n",
    "# initializtion for each cell\n",
    "for y in range(CELL_SIZE):\n",
    "    for x in range(CELL_SIZE):\n",
    "        ######x,y flip\n",
    "        base_boxes[y, x, :] = [IMAGE_SIZE / CELL_SIZE * x, \n",
    "                            IMAGE_SIZE / CELL_SIZE * y, 0, 0]\n",
    "\n",
    "base_boxes = np.resize(base_boxes, [CELL_SIZE, CELL_SIZE, 1, 4])\n",
    "base_boxes = np.tile(base_boxes, [1, 1, BOXES_PER_CELL, 1])\n",
    "def yolo_loss(predicts, labels, objects_num):\n",
    "    \"\"\"\n",
    "    Add Loss to all the trainable variables\n",
    "    Args:\n",
    "        predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "        ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "        labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "        objects_num: 1-D tensor [batch_size]\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0.\n",
    "    \n",
    "    #you can parallel the code with tf.map_fn or tf.vectorized_map (big performance gain!)\n",
    "    for i in tf.range(BATCH_SIZE):\n",
    "        predict = predicts[i, :, :, :]\n",
    "        label = labels[i, :, :]\n",
    "        object_num = objects_num[i]\n",
    "\n",
    "        for j in tf.range(object_num):\n",
    "\n",
    "            results = losses_calculation(predict, label[j:j+1, :])\n",
    "\n",
    "            loss = loss + results\n",
    "\n",
    "    return loss/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxes1, boxes2):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "    boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "    boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "\n",
    "    Return:\n",
    "    iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    ====> iou score for each cell\n",
    "    \"\"\"\n",
    "\n",
    "    #boxes1 : [4(xmin, ymin, xmax, ymax), cell_size, cell_size, boxes_per_cell]\n",
    "    boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                    boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "\n",
    "    #boxes1 : [cell_size, cell_size, boxes_per_cell, 4(xmin, ymin, xmax, ymax)]\n",
    "    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "\n",
    "    boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                    boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "    #calculate the left up point of boxes' overlap area\n",
    "    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "    #calculate the right down point of boxes overlap area\n",
    "    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "    #intersection\n",
    "    intersection = rd - lu \n",
    "\n",
    "    #the size of the intersection area\n",
    "    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "\n",
    "    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "\n",
    "    #if intersection is negative, then the boxes don't overlap\n",
    "    inter_square = mask * inter_square\n",
    "\n",
    "    #calculate the boxs1 square and boxs2 square\n",
    "    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "    return inter_square/(square1 + square2 - inter_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses_calculation(predict, label):\n",
    "    \"\"\"\n",
    "    calculate loss\n",
    "    Args:\n",
    "      predict: 3-D tensor [cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "      label : [1, 5]  (x_center, y_center, w, h, class)\n",
    "    \"\"\"\n",
    "    label = tf.reshape(label, [-1])\n",
    "\n",
    "    #Step A. calculate objects tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #turn pixel position into cell position (corner)\n",
    "    min_x = (label[0] - label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_x = (label[0] + label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_y = (label[1] - label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_y = (label[1] + label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_x = tf.floor(min_x)\n",
    "    min_x = tf.maximum(min_x,0)\n",
    "    min_y = tf.floor(min_y)\n",
    "    min_y = tf.maximum(min_y,0)\n",
    "    max_x = tf.minimum(tf.math.ceil(max_x), CELL_SIZE)\n",
    "    max_y = tf.minimum(tf.math.ceil(max_y), CELL_SIZE)\n",
    "    \n",
    "    #calculate mask of object with cells\n",
    "    onset = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "    object_mask = tf.ones(onset, tf.float32)\n",
    "\n",
    "    offset = tf.cast(tf.stack([min_y, CELL_SIZE - max_y, min_x, CELL_SIZE - max_x]), tf.int32)\n",
    "    offset = tf.reshape(offset, (2, 2))\n",
    "    object_mask = tf.pad(object_mask, offset, \"CONSTANT\")\n",
    "\n",
    "    #Step B. calculate the coordination of object center and the corresponding mask\n",
    "    #turn pixel position into cell position (center)\n",
    "    center_x = label[0] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_x = tf.floor(center_x)\n",
    "\n",
    "    center_y = label[1] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_y = tf.floor(center_y)\n",
    "\n",
    "    response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "    #calculate the coordination of object center with cells\n",
    "    objects_center_coord = tf.cast(tf.stack([center_y, CELL_SIZE - center_y - 1, \n",
    "                             center_x, CELL_SIZE - center_x - 1]), \n",
    "                             tf.int32)\n",
    "    objects_center_coord = tf.reshape(objects_center_coord, (2, 2))\n",
    "\n",
    "    #make mask\n",
    "    response = tf.pad(response, objects_center_coord, \"CONSTANT\")\n",
    "\n",
    "    #Step C. calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    predict_boxes = predict[:, :, NUM_CLASSES + BOXES_PER_CELL:]\n",
    "\n",
    "    predict_boxes = tf.reshape(predict_boxes, [CELL_SIZE, \n",
    "                                               CELL_SIZE, \n",
    "                                               BOXES_PER_CELL, 4])\n",
    "    #cell position to pixel position\n",
    "    predict_boxes = predict_boxes * [IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE, IMAGE_SIZE]\n",
    "\n",
    "    #if there's no predict_box in that cell, then the base_boxes will be calcuated with label and got iou equals 0\n",
    "    predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "    iou_predict_truth = iou(predict_boxes, label[0:4])\n",
    "\n",
    "    #calculate C tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    C = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    I = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    max_I = tf.reduce_max(I, 2, keepdims=True)\n",
    "\n",
    "    #replace large iou scores with response (object center) value\n",
    "    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (CELL_SIZE, CELL_SIZE, 1))\n",
    "\n",
    "    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    no_I = tf.ones_like(I, dtype=tf.float32) - I\n",
    "\n",
    "    p_C = tf.nn.sigmoid(predict[:, :, NUM_CLASSES:NUM_CLASSES + BOXES_PER_CELL])\n",
    "    #tf.print(p_C)\n",
    "    #calculate truth x, y, sqrt_w, sqrt_h 0-D\n",
    "    x = label[0]\n",
    "    y = label[1]\n",
    "\n",
    "    sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "    sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "\n",
    "    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    p_x = predict_boxes[:, :, :, 0]\n",
    "    p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "    p_sqrt_w = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "    p_sqrt_h = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "\n",
    "    #calculate ground truth p 1-D tensor [NUM_CLASSES]\n",
    "    P = tf.one_hot(tf.cast(label[4], tf.int32), NUM_CLASSES, dtype=tf.float32)\n",
    "\n",
    "    #calculate predicted p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "    p_P = tf.nn.sigmoid(predict[:, :, 0:NUM_CLASSES])\n",
    "\n",
    "    #class_loss\n",
    "    class_loss = tf.nn.l2_loss(tf.reshape(object_mask, (CELL_SIZE, CELL_SIZE, 1)) * (p_P - P)) * CLASS_SCALE\n",
    "\n",
    "    #object_loss\n",
    "    object_loss = tf.nn.l2_loss(I * (p_C - C)) * OBJECT_SCALE\n",
    "\n",
    "    #noobject_loss\n",
    "    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * NOOBJECT_SCALE\n",
    "\n",
    "    #coord_loss\n",
    "    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                  tf.nn.l2_loss(I * (p_y - y)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                  tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/IMAGE_SIZE +\n",
    "                  tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/IMAGE_SIZE) * COORD_SCALE\n",
    "\n",
    "    return class_loss + object_loss + noobject_loss + coord_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = DatasetGenerator(0.1)\n",
    "dataset = ddd.generate()\n",
    "dataset_val = ddd.generate_val()\n",
    "dataset.take(1)\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "train_loss_metric = tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), net=YOLO)\n",
    "manager = tf.train.CheckpointManager(ckpt, './ckpts/'+pretrain_model, max_to_keep=10,\n",
    "                                    checkpoint_name='yolo')\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "\n",
    "#  ckpt.restore('./ckpts/'+pretrain_model+'/yolo-10')\n",
    "valid_loss_metric = tf.keras.metrics.Mean(name='lossval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (四)、Epochs \n",
    "我們不僅對 Train step 觀察在梯度下降過程中的loss 下降趨勢，同時觀察validation set上loss的下降趨勢。\n",
    "根據我們運算的資源和測試，在epoch設定為 40 時，可以在運算速度以及loss下降趨勢上有較好的平衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "\n",
    "def train_step(image, labels, objects_num):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        outputs = YOLO(image)\n",
    "        \n",
    "        # class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "\n",
    "        # conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "\n",
    "        class_probs = outputs[0]#tf.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "\n",
    "        confs = outputs[1]#tf.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "\n",
    "        boxes = outputs[2]#tf.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "\n",
    "        predicts = tf.concat([class_probs, confs, boxes], 3)\n",
    "        \n",
    "        loss = yolo_loss(predicts, labels, objects_num)\n",
    "\n",
    "        train_loss_metric(loss)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    grads = tape.gradient(loss, YOLO.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, YOLO.trainable_weights))\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "\n",
    "def valid_step(image, labels, objects_num):\n",
    "        outputs = YOLO(image,training=False)\n",
    "\n",
    "        # class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "\n",
    "        # conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "\n",
    "        class_probs = outputs[0]#tf.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "\n",
    "        confs = outputs[1]#tf.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "\n",
    "        boxes = outputs[2]#tf.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "\n",
    "        predicts = tf.concat([class_probs, confs, boxes], 3)\n",
    "\n",
    "        lossval = yolo_loss(predicts, labels, objects_num)\n",
    "\n",
    "        valid_loss_metric(lossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\"{}, start training.\".format(datetime.now()))\n",
    "for i in range(EPOCHS):\n",
    "    train_loss_metric.reset_states()\n",
    "    valid_loss_metric.reset_states()\n",
    "    ckpt.epoch.assign_add(1)\n",
    "    for idx, (image, labels, objects_num) in enumerate(dataset):\n",
    "\n",
    "\n",
    "        train_step(image, labels, objects_num)\n",
    "\n",
    "        tf.print(train_loss_metric.result())\n",
    "    print(\"{}, Epoch {}: train loss {:.2f}\".format(datetime.now(), i+1, train_loss_metric.result()))\n",
    "    for idx, (image, labels, objects_num) in enumerate(dataset_val):\n",
    "\n",
    "        valid_step(image, labels, objects_num)\n",
    "        tf.print(valid_loss_metric.result())\n",
    "    print(\"{}, Epoch {}: valid loss {:.2f}\".format(datetime.now(), i+1, valid_loss_metric.result()))\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path))\n",
    "#%%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (五)、Non-max Suppression\n",
    "在助教提供的程式碼中，只會預測機率最大的Bounding Box與其類別，但在一張圖中可能會有許多不同的Object，因此我們後來採取下列方式：\n",
    "* 將confidence大於此confidence threshold的預測 bounding box留著，其餘刪掉。\n",
    "* 由於同一個物體可能被需多多個bounding box框住，所以多個高度重疊的bounding box選擇出一個。(Non-max suppression)\n",
    "* object probability 最高的bounding box 作為 true label 並計算其他與此 label 的IOU 。當 iou 高過某一個iou threshold時，視其為框住同一個物體，並將其刪除，並重複此步驟直到結束。\n",
    "\n",
    "我們有寫出自己的版本後，但發現有套件可以達到同樣的效果後，即採用套件的模式實現 Non-max suppression。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outputs(outputs):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "\n",
    "    # class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "    # conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "    # class_probs = np.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "    # confs = np.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "    # boxes = np.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "    # predicts = np.concatenate([class_probs, confs, boxes], 3)\n",
    "\n",
    "    p_classes = outputs[0]\n",
    "\n",
    "    C = outputs[1]\n",
    "\n",
    "    coordinate = outputs[2]\n",
    "\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (CELL_SIZE, CELL_SIZE, 1, 20))\n",
    "    p_classes = 1/(1+np.exp(-p_classes))\n",
    "\n",
    "\n",
    "    C = np.reshape(C, (CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 1))\n",
    "    C = 1/(1+np.exp(-C))\n",
    "\n",
    "    coordinate = np.reshape(coordinate, \n",
    "                            (CELL_SIZE, \n",
    "                             CELL_SIZE,\n",
    "                             BOXES_PER_CELL, \n",
    "                             4))\n",
    "    coordinate = coordinate * [IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE, IMAGE_SIZE]\n",
    "    coordinate = base_boxes + coordinate\n",
    "    \n",
    "    coordinate[:, :, :, 2] = np.minimum(IMAGE_SIZE * 1.0, np.maximum(0.0, coordinate[:, :, :, 2]))\n",
    "    coordinate[:, :, :, 3] = np.minimum(IMAGE_SIZE * 1.0, np.maximum(0.0, coordinate[:, :, :, 3]))\n",
    "    coordinate_tips = np.zeros_like(coordinate)\n",
    "    coordinate_tips[:,:,:,0] = coordinate[:, :, :, 0]-coordinate[:, :, :, 2]/2.\n",
    "    coordinate_tips[:,:,:,1] = coordinate[:, :, :, 0]-coordinate[:, :, :, 3]/2.\n",
    "    coordinate_tips[:,:,:,2] = coordinate[:, :, :, 0]+coordinate[:, :, :, 2]/2.\n",
    "    coordinate_tips[:,:,:,3] = coordinate[:, :, :, 0]+coordinate[:, :, :, 3]/2.\n",
    "\n",
    "    coordinate_tips = np.reshape(coordinate_tips,(1,-1,1,4))\n",
    "    #coordinate_tips = np.reshape(coordinate_tips,(-1,4))\n",
    "\n",
    "    coordinate_tips=coordinate_tips.astype(\"float32\")\n",
    "\n",
    "    #X = np.reshape(C,-1)\n",
    "    P = C * p_classes\n",
    "    P = np.reshape(P,(1,-1,20))\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "    index = tf.image.combined_non_max_suppression(coordinate_tips,P,5,2,iou_threshold=0.2,clip_boxes=False,score_threshold=0.02)\n",
    "    #index = tf.image.non_max_suppression(coordinate_tips,X,3, iou_threshold=0.5,score_threshold=0.1)\n",
    "    #max_coordinate = coordinate_tips[index,:]\n",
    "    # max_conf = X[[index]]\n",
    "    # index = np.unravel_index(index, C.shape)\n",
    "    # class_num = np.argmax(p_classes[index[0],index[1],0,:],1)\n",
    "    end=np.sum(index[1]!=0)\n",
    "    \n",
    "    return index[0][0,0:end,0], index[0][0,0:end,1], index[0][0,0:end,2], index[0][0,0:end,3], index[2][0,0:end], index[1][0,0:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手刻版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outputs(outputs):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "    class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "    conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "    class_probs = np.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "    confs = np.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "    boxes = np.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "    BOXES = boxes.reshape(7, 7,2,4)\n",
    "    predicts = np.concatenate([class_probs, confs, boxes], 3)\n",
    "\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (CELL_SIZE, CELL_SIZE, 1, 20))\n",
    "    C = np.reshape(C, (CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 1))\n",
    "\n",
    "    P_threshold = 0.6\n",
    "    iou_threshold = 0.8\n",
    "    C_threshold = 0.4 # np.mean(C)\n",
    "\n",
    "\n",
    "    C = C*(C>C_threshold)    \n",
    "    P = C * p_classes\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "\n",
    "    #choose the most confidence one\n",
    "\n",
    "    output = []\n",
    "\n",
    "    num_of_candidator = np.sum(P>P_threshold)\n",
    "    # 最少框一個\n",
    "    if num_of_candidator == 0:\n",
    "        num_of_candidator = 1\n",
    "\n",
    "    while num_of_candidator >0:\n",
    "        max_conf = np.max(P)\n",
    "        index = np.argmax(P)\n",
    "        index = np.unravel_index(index, P.shape)\n",
    "\n",
    "        max_class = np.max(P[index[0],index[1],:])\n",
    "        # P[index[0],index[1],index[2],:] = 0.\n",
    "        class_num = index[3]\n",
    "\n",
    "        max_coordinate = BOXES[index[0], index[1], index[2], :]\n",
    "\n",
    "        xcenter = max_coordinate[0]\n",
    "        ycenter = max_coordinate[1]\n",
    "        w = max_coordinate[2]\n",
    "        h = max_coordinate[3]\n",
    "\n",
    "        xcenter = (index[1] + xcenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "        ycenter = (index[0] + ycenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "\n",
    "        w = w * IMAGE_SIZE\n",
    "        h = h * IMAGE_SIZE\n",
    "\n",
    "        xmin = xcenter - w/2.0\n",
    "        ymin = ycenter - h/2.0\n",
    "\n",
    "        xmax = xmin + w\n",
    "        ymax = ymin + h\n",
    "\n",
    "        IOU = iou(tf.constant(max_coordinate),tf.constant(BOXES))\n",
    "        IOU = IOU.numpy().reshape(1,7,7,2)\n",
    "        C = C*(IOU<iou_threshold)\n",
    "        P = C * p_classes\n",
    "        num_of_candidator = np.sum(P>P_threshold)\n",
    "        output.append([xmin, ymin, xmax, ymax, class_num, max_conf])\n",
    "        output=np.array(output)\n",
    "\n",
    "\n",
    "    return output[:,0],output[:,1],output[:,2],output[:,3],output[:,4],output[:,5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_files = open('pascal_voc_testing_data.txt')\n",
    "test_img_dir = 'VOCdevkit_test/VOC2007/JPEGImages/'\n",
    "test_images = []\n",
    "\n",
    "for line in test_img_files:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    test_images.append(ss[0])\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "def load_img_data(image_name):\n",
    "    image_file = tf.io.read_file(test_img_dir+image_name)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "    #image = (image/255) * 2 - 1\n",
    "    if pretrain_model == 'Resnet':\n",
    "        image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "    elif pretrain_model == 'Xception':\n",
    "        image = tf.keras.applications.xception.preprocess_input(image)\n",
    "    elif pretrain_model == 'EfficientNetB0':\n",
    "        image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
    "    elif pretrain_model == 'DenseNet121':\n",
    "            image = tf.keras.applications.densenet.preprocess_input(image)\n",
    "    return image_name, image, h, w\n",
    "\n",
    "test_dataset = test_dataset.map(load_img_data, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32)\n",
    "ckpt = tf.train.Checkpoint(net=YOLO)\n",
    "ckpt.restore('./ckpts/'+pretrain_model+'/yolo-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def prediction_step(img):\n",
    "    return YOLO(img, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('./test_predictionJJ.txt', 'w')\n",
    "\n",
    "for img_name, test_img, img_h, img_w in test_dataset:\n",
    "    batch_num = img_name.shape[0]\n",
    "    for i in range(batch_num):\n",
    "        xmin, ymin, xmax, ymax, class_num, conf = process_outputs(prediction_step(test_img[i:i+1]))\n",
    "        xmin =tf.cast(xmin,tf.float64)\n",
    "        xmax =tf.cast(xmax,tf.float64)\n",
    "        ymin =tf.cast(ymin,tf.float64)\n",
    "        ymax =tf.cast(ymax,tf.float64)\n",
    "        class_num = tf.cast(class_num,tf.int32)\n",
    "        xmin, ymin, xmax, ymax = xmin*(img_w[i:i+1]/IMAGE_SIZE), ymin*(img_h[i:i+1]/IMAGE_SIZE), xmax*(img_w[i:i+1]/IMAGE_SIZE), ymax*(img_h[i:i+1]/IMAGE_SIZE)\n",
    "        output_file.write(img_name[i:i+1].numpy()[0].decode('ascii'))\n",
    "        #img filename, xmin, ymin, xmax, ymax, class, confidence\n",
    "        if xmin.shape==1 :\n",
    "            output_file.write(\" %d %d %d %d %d %f\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "            output_file.write(\"\\n\")\n",
    "        else:\n",
    "            for xmin, ymin, xmax, ymax, class_num, conf in zip(xmin, ymin, xmax, ymax, class_num, conf):\n",
    "                output_file.write(\" %d %d %d %d %d %f\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "            output_file.write(\"\\n\")\n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.insert(0, './evaluate')\n",
    "import evaluate\n",
    "# os.chdir('/home/rabbit2/contest2/datalab-cup2-object-detection-2020/JBR')\n",
    "\n",
    "#evaluate.evaluate(\"input prediction file name\", \"desire output csv file name\")\n",
    "evaluate.evaluate('./test_predictionJJ.txt', './output_fileJJ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "np_img = cv2.imread('./VOCdevkit_test/VOC2007/JPEGImages/000179.jpg')\n",
    "resized_img = cv2.resize(np_img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "resized_img = np_img\n",
    "np_img = np_img.astype(np.float32)\n",
    "\n",
    "if pretrain_model == 'Resnet':\n",
    "    np_img = tf.keras.applications.resnet.preprocess_input(np_img)\n",
    "elif pretrain_model == 'Xception':\n",
    "    np_img = tf.keras.applications.xception.preprocess_input(np_img)\n",
    "elif pretrain_model == 'EfficientNetB0':\n",
    "    np_img = tf.keras.applications.efficientnet.preprocess_input(np_img)\n",
    "elif pretrain_model == 'DenseNet121':\n",
    "    np_img = tf.keras.applications.densenet.preprocess_input(np_img)\n",
    "\n",
    "y_pred = YOLO(np_img, training=False)\n",
    "xmin, ymin, xmax, ymax, class_num, conf = process_outputs(y_pred)\n",
    "\n",
    "class_num = tf.cast(class_num,tf.int32)\n",
    "\n",
    "class_name = [classes_name[i] for i in class_num]\n",
    "\n",
    "\n",
    "for i in range(len(xmin)):\n",
    "    cv2.rectangle(resized_img, (int(xmin[i]), int(ymin[i])), (int(xmax[i]), int(ymax[i])), (0, 255, 255), 3)\n",
    "    cv2.putText(resized_img, class_name[i], (0, 200), 2, 1.5, (0, 255, 255), 2)\n",
    "\n",
    "plt.imshow(resized_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、Summary\n",
    "* 我們曾經嘗試用ResNet50、ResNet152、Xception、EfficientNetB0、DenseNet121、VGG16、VGG19等模型進行預測，在只做上述data preprocessing的情況下，直接去train的效果表現一般。\n",
    "* 最後我們在Kaggle上private score最好的是用EfficientNetB0的模型train出來的。\n",
    "* 由於運算資源和時間因素，我們的模型其實迭代次數並不多，相信若迭代次數更多，模型表現應該可以更好。\n",
    "* 由於不同的pre-trained model 其實也可以代表不同模型預測出的不同結果，也就意味著，我們或許可以再利用Non-max suppression 的方式，將模型做 ensemble，可惜因時間因素，並不能實現此階段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
